{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "colors = sns.color_palette('pastel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>new_session_id</th>\n",
       "      <th>target</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>shipment_fee</th>\n",
       "      <th>ADD_TO_CART_COUNT</th>\n",
       "      <th>SEARCH_COUNT</th>\n",
       "      <th>ADD_PROMO_COUNT</th>\n",
       "      <th>BOOKING_COUNT</th>\n",
       "      <th>ITEM_DETAIL_COUNT</th>\n",
       "      <th>limit_ship</th>\n",
       "      <th>PAGE_VIEW</th>\n",
       "      <th>total_promo</th>\n",
       "      <th>total_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>f03b6825-1e6e-4916-bf71-f94ecbcbaee5_7952132</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36673b2f-940a-42b5-994d-1cce4796b55f_1792149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36673b2f-940a-42b5-994d-1cce4796b55f_1792150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36673b2f-940a-42b5-994d-1cce4796b55f_1792151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36673b2f-940a-42b5-994d-1cce4796b55f_1792152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  customer_id                                new_session_id  \\\n",
       "0           0          3.0  f03b6825-1e6e-4916-bf71-f94ecbcbaee5_7952132   \n",
       "1           1          3.0  36673b2f-940a-42b5-994d-1cce4796b55f_1792149   \n",
       "2           2          3.0  36673b2f-940a-42b5-994d-1cce4796b55f_1792150   \n",
       "3           3          3.0  36673b2f-940a-42b5-994d-1cce4796b55f_1792151   \n",
       "4           4          3.0  36673b2f-940a-42b5-994d-1cce4796b55f_1792152   \n",
       "\n",
       "   target  total_amount  shipment_fee  ADD_TO_CART_COUNT  SEARCH_COUNT  \\\n",
       "0       1             4             0                2.0           0.0   \n",
       "1       0             0             0                0.0           0.0   \n",
       "2       0             0             0                2.0           0.0   \n",
       "3       0             0             0                1.0           0.0   \n",
       "4       1             1             2                0.0           0.0   \n",
       "\n",
       "   ADD_PROMO_COUNT  BOOKING_COUNT  ITEM_DETAIL_COUNT  limit_ship  PAGE_VIEW  \\\n",
       "0              1.0            1.0                0.0           1          8   \n",
       "1              0.0            0.0                0.0           0          1   \n",
       "2              0.0            0.0                0.0           0          2   \n",
       "3              0.0            0.0                0.0           0          1   \n",
       "4              0.0            1.0                0.0           3          1   \n",
       "\n",
       "   total_promo  total_session  \n",
       "0            3              3  \n",
       "1            0              3  \n",
       "2            0              3  \n",
       "3            0              3  \n",
       "4            0              3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_session'] = df.groupby('customer_id')['new_session_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>new_session_id</th>\n",
       "      <th>target</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>shipment_fee</th>\n",
       "      <th>ADD_TO_CART_COUNT</th>\n",
       "      <th>SEARCH_COUNT</th>\n",
       "      <th>ADD_PROMO_COUNT</th>\n",
       "      <th>BOOKING_COUNT</th>\n",
       "      <th>ITEM_DETAIL_COUNT</th>\n",
       "      <th>limit_ship</th>\n",
       "      <th>PAGE_VIEW</th>\n",
       "      <th>total_promo</th>\n",
       "      <th>total_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>f03b6825-1e6e-4916-bf71-f94ecbcbaee5_7952132</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36673b2f-940a-42b5-994d-1cce4796b55f_1792149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36673b2f-940a-42b5-994d-1cce4796b55f_1792150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36673b2f-940a-42b5-994d-1cce4796b55f_1792151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36673b2f-940a-42b5-994d-1cce4796b55f_1792152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  customer_id                                new_session_id  \\\n",
       "0           0          3.0  f03b6825-1e6e-4916-bf71-f94ecbcbaee5_7952132   \n",
       "1           1          3.0  36673b2f-940a-42b5-994d-1cce4796b55f_1792149   \n",
       "2           2          3.0  36673b2f-940a-42b5-994d-1cce4796b55f_1792150   \n",
       "3           3          3.0  36673b2f-940a-42b5-994d-1cce4796b55f_1792151   \n",
       "4           4          3.0  36673b2f-940a-42b5-994d-1cce4796b55f_1792152   \n",
       "\n",
       "   target  total_amount  shipment_fee  ADD_TO_CART_COUNT  SEARCH_COUNT  \\\n",
       "0       1             4             0                2.0           0.0   \n",
       "1       0             0             0                0.0           0.0   \n",
       "2       0             0             0                2.0           0.0   \n",
       "3       0             0             0                1.0           0.0   \n",
       "4       1             1             2                0.0           0.0   \n",
       "\n",
       "   ADD_PROMO_COUNT  BOOKING_COUNT  ITEM_DETAIL_COUNT  limit_ship  PAGE_VIEW  \\\n",
       "0              1.0            1.0                0.0           1          8   \n",
       "1              0.0            0.0                0.0           0          1   \n",
       "2              0.0            0.0                0.0           0          2   \n",
       "3              0.0            0.0                0.0           0          1   \n",
       "4              0.0            1.0                0.0           3          1   \n",
       "\n",
       "   total_promo  total_session  \n",
       "0            3            321  \n",
       "1            0            321  \n",
       "2            0            321  \n",
       "3            0            321  \n",
       "4            0            321  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'customer_id', 'new_session_id', 'target', 'total_amount',\n",
       "       'shipment_fee', 'ADD_TO_CART_COUNT', 'SEARCH_COUNT', 'ADD_PROMO_COUNT',\n",
       "       'BOOKING_COUNT', 'ITEM_DETAIL_COUNT', 'limit_ship', 'PAGE_VIEW',\n",
       "       'total_promo', 'total_session'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['total_amount','shipment_fee', 'ADD_TO_CART_COUNT', 'SEARCH_COUNT', 'ADD_PROMO_COUNT',\n",
    "       'BOOKING_COUNT', 'ITEM_DETAIL_COUNT', 'limit_ship', 'PAGE_VIEW',\n",
    "       'total_promo', 'total_session']]\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data training:  (3041769, 11)\n",
      "data testing:  (1303616, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)\n",
    "print(\"data training: \", X_train.shape)\n",
    "print(\"data testing: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3041769,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,precision_score,recall_score,roc_auc_score,f1_score,roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"LogisticRegression\" : LogisticRegression(),\n",
    "    \"KNeighbors\" : KNeighborsClassifier(),\n",
    "    \"DecisionTree\" : DecisionTreeClassifier(),\n",
    "    \"RandomForest\" : RandomForestClassifier(n_estimators=250,max_depth=12,min_samples_leaf=16),\n",
    "    \"XGBoost\" : XGBClassifier(max_depth=12,\n",
    "                              n_estimators=250,\n",
    "                              min_child_weight=8, \n",
    "                              subsample=0.8, \n",
    "                              learning_rate =0.02,    \n",
    "                              seed=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = pd.DataFrame(columns=['classifiers','accuracy','presicion','recall','f1_score','fpr','tpr','auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.51%\n",
      "Class probabilities:\n",
      "[[0.89065837 0.10934163]\n",
      " [0.17320445 0.82679555]\n",
      " [0.76901285 0.23098715]\n",
      " ...\n",
      " [0.79531974 0.20468026]\n",
      " [0.93022534 0.06977466]\n",
      " [0.85909013 0.14090987]]\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀 모델 생성\n",
    "model = LogisticRegression()\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# 각 클래스에 속할 확률 출력\n",
    "print(\"Class probabilities:\\n{}\".format(y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2685437    0\n",
       "3856564    1\n",
       "3144437    0\n",
       "3059282    0\n",
       "948815     0\n",
       "          ..\n",
       "2058718    0\n",
       "312003     0\n",
       "3082701    0\n",
       "3858954    0\n",
       "3639091    0\n",
       "Name: target, Length: 1303616, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_series = pd.Series(y_pred, index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_array = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2685437    0\n",
       "3856564    1\n",
       "3144437    0\n",
       "3059282    0\n",
       "948815     0\n",
       "          ..\n",
       "2058718    0\n",
       "312003     0\n",
       "3082701    0\n",
       "3858954    0\n",
       "3639091    0\n",
       "Length: 1303616, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mj985\\section5\\ecommerce_project\\model\\check_accuracy.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mj985/section5/ecommerce_project/model/check_accuracy.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# confusion matrix 출력\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mj985/section5/ecommerce_project/model/check_accuracy.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConfusion Matrix:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(confusion_matrix(y_test, y_pred_series)))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mj985/section5/ecommerce_project/model/check_accuracy.ipynb#X46sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# precision, recall, f1-score 출력\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mj985/section5/ecommerce_project/model/check_accuracy.ipynb#X46sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPrecision Score: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(precision_score(y_test, y_pred_series, average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "# confusion matrix 출력\n",
    "print(\"Confusion Matrix:\\n{}\".format(confusion_matrix(y_test, y_pred_series)))\n",
    "\n",
    "# precision, recall, f1-score 출력\n",
    "print(\"Precision Score: {:.2f}%\".format(precision_score(y_test, y_pred_series, average=\"weighted\") * 100))\n",
    "print(\"Recall Score: {:.2f}%\".format(recall_score(y_test, y_pred_series, average=\"weighted\") * 100))\n",
    "print(\"F1 Score: {:.2f}%\".format(f1_score(y_test, y_pred_series, average=\"weighted\") * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mj985\\section5\\ecommerce_project\\model\\check_accuracy.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mj985/section5/ecommerce_project/model/check_accuracy.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# confusion matrix 출력\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mj985/section5/ecommerce_project/model/check_accuracy.ipynb#X50sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m confusion_matrix \u001b[39m=\u001b[39m confusion_matrix(y_test, y_pred_series)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mj985/section5/ecommerce_project/model/check_accuracy.ipynb#X50sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConfusion Matrix:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(confusion_matrix))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mj985/section5/ecommerce_project/model/check_accuracy.ipynb#X50sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# confusion matrix 시각화\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "# confusion matrix 출력\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred_series)\n",
    "print(\"Confusion Matrix:\\n{}\".format(confusion_matrix))\n",
    "\n",
    "# confusion matrix 시각화\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=model.classes_)\n",
    "disp.plot(cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.777027\n",
       "1    0.222973\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.34%\n",
      "Class probabilities:\n",
      "[[0.91629195 0.08370807]\n",
      " [0.02611965 0.97388035]\n",
      " [0.478011   0.521989  ]\n",
      " ...\n",
      " [0.83330333 0.16669664]\n",
      " [0.9148429  0.08515711]\n",
      " [0.95534843 0.04465159]]\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(max_depth=12, n_estimators=250,min_child_weight=8,subsample=0.8, learning_rate =0.02, seed=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# 각 클래스에 속할 확률 출력\n",
    "print(\"Class probabilities:\\n{}\".format(y_pred_proba))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[977473  34935]\n",
      " [143093 148115]]\n",
      "Precision Score: 85.82%\n",
      "Recall Score: 86.34%\n",
      "F1 Score: 85.13%\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix 출력\n",
    "print(\"Confusion Matrix:\\n{}\".format(confusion_matrix(y_test, y_pred)))\n",
    "\n",
    "# precision, recall, f1-score 출력\n",
    "print(\"Precision Score: {:.2f}%\".format(precision_score(y_test, y_pred, average=\"weighted\") * 100))\n",
    "print(\"Recall Score: {:.2f}%\".format(recall_score(y_test, y_pred, average=\"weighted\") * 100))\n",
    "print(\"F1 Score: {:.2f}%\".format(f1_score(y_test, y_pred, average=\"weighted\") * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[977473  34935]\n",
      " [143093 148115]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x21fffde7340>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix 출력\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n{}\".format(confusion_matrix))\n",
    "\n",
    "# confusion matrix 시각화\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=model.classes_)\n",
    "disp.plot(cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "95056/95056 [==============================] - 131s 1ms/step - loss: 0.3865 - accuracy: 0.8594\n",
      "Epoch 2/10\n",
      "95056/95056 [==============================] - 126s 1ms/step - loss: 0.3773 - accuracy: 0.8612\n",
      "Epoch 3/10\n",
      "95056/95056 [==============================] - 124s 1ms/step - loss: 0.3763 - accuracy: 0.8617\n",
      "Epoch 4/10\n",
      "95056/95056 [==============================] - 125s 1ms/step - loss: 0.3757 - accuracy: 0.8619\n",
      "Epoch 5/10\n",
      "95056/95056 [==============================] - 119s 1ms/step - loss: 0.3753 - accuracy: 0.8619\n",
      "Epoch 6/10\n",
      "95056/95056 [==============================] - 119s 1ms/step - loss: 0.3753 - accuracy: 0.8619\n",
      "Epoch 7/10\n",
      "95056/95056 [==============================] - 120s 1ms/step - loss: 0.3749 - accuracy: 0.8619\n",
      "Epoch 8/10\n",
      "95056/95056 [==============================] - 119s 1ms/step - loss: 0.3748 - accuracy: 0.8620\n",
      "Epoch 9/10\n",
      "95056/95056 [==============================] - 119s 1ms/step - loss: 0.3747 - accuracy: 0.8620\n",
      "Epoch 10/10\n",
      "95056/95056 [==============================] - 120s 1ms/step - loss: 0.3746 - accuracy: 0.8621\n",
      "40738/40738 [==============================] - 42s 1ms/step - loss: 0.3763 - accuracy: 0.8620\n",
      "Test accuracy: 0.8619639277458191\n",
      "40738/40738 [==============================] - 37s 895us/step\n",
      "Accuracy: 0.8619639525749914\n",
      "F1 score: 0.6189457724169476\n",
      "Recall: 0.5018509106892668\n",
      "Precision: 0.8073128424960226\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성\n",
    "deep_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "deep_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "deep_model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_acc = deep_model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# 예측값 계산\n",
    "y_pred = deep_model.predict(X_test)\n",
    "\n",
    "# 지표 계산\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy:', acc)\n",
    "print('F1 score:', f1)\n",
    "print('Recall:', recall)\n",
    "print('Precision:', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23764/23764 [==============================] - 35s 1ms/step - loss: 0.3983 - accuracy: 0.8572\n",
      "Epoch 2/10\n",
      "23764/23764 [==============================] - 30s 1ms/step - loss: 0.3787 - accuracy: 0.8609\n",
      "Epoch 3/10\n",
      "23764/23764 [==============================] - 29s 1ms/step - loss: 0.3760 - accuracy: 0.8619\n",
      "Epoch 4/10\n",
      "23764/23764 [==============================] - 36s 2ms/step - loss: 0.3750 - accuracy: 0.8620\n",
      "Epoch 5/10\n",
      "23764/23764 [==============================] - 37s 2ms/step - loss: 0.3744 - accuracy: 0.8622\n",
      "Epoch 6/10\n",
      "23764/23764 [==============================] - 35s 1ms/step - loss: 0.3740 - accuracy: 0.8623\n",
      "Epoch 7/10\n",
      "23764/23764 [==============================] - 37s 2ms/step - loss: 0.3738 - accuracy: 0.8623\n",
      "Epoch 8/10\n",
      "23764/23764 [==============================] - 35s 1ms/step - loss: 0.3735 - accuracy: 0.8623\n",
      "Epoch 9/10\n",
      "23764/23764 [==============================] - 36s 2ms/step - loss: 0.3734 - accuracy: 0.8623\n",
      "Epoch 10/10\n",
      "23764/23764 [==============================] - 36s 2ms/step - loss: 0.3732 - accuracy: 0.8625\n",
      "40738/40738 [==============================] - 48s 1ms/step - loss: 0.3730 - accuracy: 0.8626\n",
      "Test accuracy: 0.862559974193573\n",
      "40738/40738 [==============================] - 41s 1ms/step\n",
      "Accuracy: 0.8625599869900339\n",
      "F1 score: 0.62524863993173\n",
      "Recall: 0.5132619982967501\n",
      "Precision: 0.799741028288914\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성\n",
    "deep_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "deep_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "deep_model.fit(X_train, y_train, epochs=10, batch_size = 128)\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_acc = deep_model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# 예측값 계산\n",
    "y_pred = deep_model.predict(X_test)\n",
    "\n",
    "# 지표 계산\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy:', acc)\n",
    "print('F1 score:', f1)\n",
    "print('Recall:', recall)\n",
    "print('Precision:', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11882/11882 [==============================] - 20s 2ms/step - loss: 0.4098 - accuracy: 0.8554\n",
      "Epoch 2/10\n",
      "11882/11882 [==============================] - 19s 2ms/step - loss: 0.3873 - accuracy: 0.8596\n",
      "Epoch 3/10\n",
      "11882/11882 [==============================] - 20s 2ms/step - loss: 0.3799 - accuracy: 0.8609\n",
      "Epoch 4/10\n",
      "11882/11882 [==============================] - 21s 2ms/step - loss: 0.3767 - accuracy: 0.8615\n",
      "Epoch 5/10\n",
      "11882/11882 [==============================] - 20s 2ms/step - loss: 0.3754 - accuracy: 0.8617\n",
      "Epoch 6/10\n",
      "11882/11882 [==============================] - 19s 2ms/step - loss: 0.3748 - accuracy: 0.8619\n",
      "Epoch 7/10\n",
      "11882/11882 [==============================] - 20s 2ms/step - loss: 0.3744 - accuracy: 0.8620\n",
      "Epoch 8/10\n",
      "11882/11882 [==============================] - 19s 2ms/step - loss: 0.3741 - accuracy: 0.8621\n",
      "Epoch 9/10\n",
      "11882/11882 [==============================] - 19s 2ms/step - loss: 0.3738 - accuracy: 0.8622\n",
      "Epoch 10/10\n",
      "11882/11882 [==============================] - 18s 1ms/step - loss: 0.3736 - accuracy: 0.8622\n",
      "40738/40738 [==============================] - 45s 1ms/step - loss: 0.3734 - accuracy: 0.8623\n",
      "Test accuracy: 0.8623175621032715\n",
      "40738/40738 [==============================] - 39s 967us/step\n",
      "Accuracy: 0.8623175843193087\n",
      "F1 score: 0.6191889638315975\n",
      "Recall: 0.5010817010521689\n",
      "Precision: 0.8101435194181495\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성\n",
    "deep_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "deep_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "deep_model.fit(X_train, y_train, epochs=10, batch_size = 256)\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_acc = deep_model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# 예측값 계산\n",
    "y_pred = deep_model.predict(X_test)\n",
    "\n",
    "# 지표 계산\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy:', acc)\n",
    "print('F1 score:', f1)\n",
    "print('Recall:', recall)\n",
    "print('Precision:', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 4.229989611145515e-07, 1: 1.4755856968527232e-06}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 클래스별 샘플 수 계산\n",
    "n_positive = np.sum(y_train == 1)\n",
    "n_negative = np.sum(y_train == 0)\n",
    "\n",
    "# 클래스별 가중치 계산\n",
    "weight_for_0 = 1 / n_negative\n",
    "weight_for_1 = 1 / n_positive\n",
    "\n",
    "# 클래스별 가중치를 딕셔너리로 저장\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47528/47528 [==============================] - 72s 2ms/step - loss: 3.5178e-07 - accuracy: 0.8387\n",
      "Epoch 2/10\n",
      "47528/47528 [==============================] - 68s 1ms/step - loss: 3.2697e-07 - accuracy: 0.8252\n",
      "Epoch 3/10\n",
      "47528/47528 [==============================] - 68s 1ms/step - loss: 3.2689e-07 - accuracy: 0.8254\n",
      "Epoch 4/10\n",
      "47528/47528 [==============================] - 68s 1ms/step - loss: 3.2685e-07 - accuracy: 0.8252\n",
      "Epoch 5/10\n",
      "47528/47528 [==============================] - 70s 1ms/step - loss: 3.2678e-07 - accuracy: 0.8252\n",
      "Epoch 6/10\n",
      "47528/47528 [==============================] - 69s 1ms/step - loss: 3.2674e-07 - accuracy: 0.8252\n",
      "Epoch 7/10\n",
      "47528/47528 [==============================] - 69s 1ms/step - loss: 3.2675e-07 - accuracy: 0.8251\n",
      "Epoch 8/10\n",
      "47528/47528 [==============================] - 71s 1ms/step - loss: 3.2672e-07 - accuracy: 0.8251\n",
      "Epoch 9/10\n",
      "47528/47528 [==============================] - 69s 1ms/step - loss: 3.2673e-07 - accuracy: 0.8248\n",
      "Epoch 10/10\n",
      "47528/47528 [==============================] - 70s 1ms/step - loss: 3.2666e-07 - accuracy: 0.8247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22022198bb0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "deep_model.fit(X_train, y_train, epochs=10, batch_size=64, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40738/40738 [==============================] - 39s 944us/step\n",
      "Accuracy: 0.826833975649271\n",
      "F1 score: 0.6246791162895867\n",
      "Recall: 0.6451093376555589\n",
      "Precision: 0.6055031973595998\n"
     ]
    }
   ],
   "source": [
    "# 예측값 계산\n",
    "y_pred = deep_model.predict(X_test)\n",
    "\n",
    "# 지표 계산\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy:', acc)\n",
    "print('F1 score:', f1)\n",
    "print('Recall:', recall)\n",
    "print('Precision:', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1303616,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mj985\\anaconda3\\envs\\assign\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 데이터를 train, validation, test로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# 각 모델의 하이퍼 파라미터 후보를 정의\n",
    "lr_param_grid = {'C': [0.01, 0.1, 1, 10]}\n",
    "knn_param_grid = {'n_neighbors': [3, 5, 7]}\n",
    "dt_param_grid = {'max_depth': [3, 5, 7]}\n",
    "rf_param_grid = {'n_estimators': [100, 300], 'max_depth': [3, 5, 7]}\n",
    "xgb_param_grid = {'n_estimators': [100, 300], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1]}\n",
    "cat_param_grid = {'iterations': [100, 300], 'depth': [3, 5, 7], 'learning_rate': [0.01, 0.1]}\n",
    "\n",
    "# 각 모델에 대해 그리드 서치 수행\n",
    "lr_gs = GridSearchCV(LogisticRegression(), lr_param_grid)\n",
    "lr_gs.fit(X_train, y_train)\n",
    "\n",
    "knn_gs = GridSearchCV(KNeighborsClassifier(), knn_param_grid)\n",
    "knn_gs.fit(X_train, y_train)\n",
    "\n",
    "dt_gs = GridSearchCV(DecisionTreeClassifier(), dt_param_grid)\n",
    "dt_gs.fit(X_train, y_train)\n",
    "\n",
    "rf_gs = GridSearchCV(RandomForestClassifier(), rf_param_grid)\n",
    "rf_gs.fit(X_train, y_train)\n",
    "\n",
    "xgb_gs = GridSearchCV(XGBClassifier(), xgb_param_grid)\n",
    "xgb_gs.fit(X_train, y_train)\n",
    "\n",
    "cat_gs = GridSearchCV(CatBoostClassifier(verbose=0), cat_param_grid)\n",
    "cat_gs.fit(X_train, y_train)\n",
    "\n",
    "# 각 모델에서 최적의 하이퍼 파라미터와 예측 결과를 저장\n",
    "lr_best_params = lr_gs.best_params_\n",
    "lr_pred = lr_gs.predict(X_val)\n",
    "\n",
    "knn_best_params = knn_gs.best_params_\n",
    "knn_pred = knn_gs.predict(X_val)\n",
    "\n",
    "dt_best_params = dt_gs.best_params_\n",
    "dt_pred = dt_gs.predict(X_val)\n",
    "\n",
    "rf_best_params = rf_gs.best_params_\n",
    "rf_pred = rf_gs.predict(X_val)\n",
    "\n",
    "xgb_best_params = xgb_gs.best_params_\n",
    "xgb_pred = xgb_gs.predict(X_val)\n",
    "\n",
    "cat_best_params = cat_gs.best_params_\n",
    "cat_pred = cat_gs.predict(X_val)\n",
    "\n",
    "# 각 모델의 성능 평가 지표 계산\n",
    "lr_acc = accuracy_score(y_val, lr_pred)\n",
    "lr_precision = precision_score(y_val, lr_pred)\n",
    "lr_recall = recall_score(y_val, lr_pred)\n",
    "lr_f1_score = f1_score(y_val, lr_pred)\n",
    "\n",
    "knn_acc = accuracy_score(y_val, knn_pred)\n",
    "knn_precision = precision_score(y_val, knn_pred)\n",
    "knn_recall = recall_score(y_val, knn_pred)\n",
    "knn_f1_score = f1_score(y_val, knn_pred)\n",
    "\n",
    "dt_acc = accuracy_score(y_val, dt_pred)\n",
    "dt_precision = precision_score(y_val, dt_pred)\n",
    "dt_recall = recall_score(y_val, dt_pred)\n",
    "dt_f1_score = f1_score(y_val, dt_pred)\n",
    "\n",
    "rf_acc = accuracy_score(y_val, rf_pred)\n",
    "rf_precision = precision_score(y_val, rf_pred)\n",
    "rf_recall = recall_score(y_val, rf_pred)\n",
    "rf_f1_score = f1_score(y_val, rf_pred)\n",
    "\n",
    "xgb_acc = accuracy_score(y_val, xgb_pred)\n",
    "xgb_precision = precision_score(y_val, xgb_pred)\n",
    "xgb_recall = recall_score(y_val, xgb_pred)\n",
    "xgb_f1_score = f1_score(y_val, xgb_pred)\n",
    "\n",
    "cat_acc = accuracy_score(y_val, cat_pred)\n",
    "cat_precision = precision_score(y_val, cat_pred)\n",
    "cat_recall = recall_score(y_val, cat_pred)\n",
    "cat_f1_score = f1_score(y_val, cat_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 출력\n",
    "print(\"Logistic Regression:\")\n",
    "print(\"Accuracy:\", lr_acc)\n",
    "print(\"Precision:\", lr_precision)\n",
    "print(\"Recall:\", lr_recall)\n",
    "print(\"F1 Score:\", lr_f1_score)\n",
    "\n",
    "print(\"K-Nearest Neighbors:\")\n",
    "print(\"Accuracy:\", knn_acc)\n",
    "print(\"Precision:\", knn_precision)\n",
    "print(\"Recall:\", knn_recall)\n",
    "print(\"F1 Score:\", knn_f1_score)\n",
    "\n",
    "print(\"Decision Tree:\")\n",
    "print(\"Accuracy:\", dt_acc)\n",
    "print(\"Precision:\", dt_precision)\n",
    "print(\"Recall:\", dt_recall)\n",
    "print(\"F1 Score:\", dt_f1_score)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(\"Accuracy:\", rf_acc)\n",
    "print(\"Precision:\", rf_precision)\n",
    "print(\"Recall:\", rf_recall)\n",
    "print(\"F1 Score:\", rf_f1_score)\n",
    "\n",
    "print(\"XGBoost:\")\n",
    "print(\"Accuracy:\", xgb_acc)\n",
    "print(\"Precision:\", xgb_precision)\n",
    "print(\"Recall:\", xgb_recall)\n",
    "print(\"F1 Score:\", xgb_f1_score)\n",
    "\n",
    "print(\"CatBoost:\")\n",
    "print(\"Accuracy:\", cat_acc)\n",
    "print(\"Precision:\", cat_precision)\n",
    "print(\"Recall:\", cat_recall)\n",
    "print(\"F1 Score:\", cat_f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
